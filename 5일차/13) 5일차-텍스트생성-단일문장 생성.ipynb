{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 생성 - 단일 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 모듈 import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, RNN, LSTM, GRU, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "d_path = './data/4_문어체_한국문화_190920.xlsx'\n",
    "xlsx = pd.read_excel(d_path)\n",
    "xlsx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "print(xlsx['원문'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 데이터 확인\n",
    "sentences = xlsx['원문'].values\n",
    "print(len(sentences))\n",
    "print(sentences[:5])\n",
    "sentences = sentences[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 및 words_set 생성\n",
    "okt = Okt()\n",
    "words_set = set()\n",
    "max_len = 0\n",
    "for ix, sentence in enumerate(sentences):\n",
    "    words = [word for word, _ in okt.pos(sentence)]\n",
    "    if len(words) > max_len:\n",
    "        max_len = len(words)\n",
    "    words_set.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_set 확인\n",
    "print(len(words_set))\n",
    "words_set = list(sorted(words_set))\n",
    "words_set.insert(0, '')\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 만들기\n",
    "train_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    words = [words_set.index(word) for word, _ in okt.pos(sentence)]\n",
    "    if len(words) > 3:\n",
    "        for i in range(1, len(words)):\n",
    "            train_sentence = words[:i+1]\n",
    "            for _ in range(max_len-len(train_sentence)):\n",
    "                train_sentence.insert(0, 0)\n",
    "            train_sentences.append(train_sentence)\n",
    "train_sentences = np.asarray(train_sentences).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 확인\n",
    "print(train_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력, 출력 나누기\n",
    "x_train = train_sentences[:, :-1]\n",
    "y_train = train_sentences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력, 출력 데이터 확인\n",
    "pprint(x_train[:5])\n",
    "pprint(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 데이터를 One hot 인코딩\n",
    "y_train = to_categorical(y_train, num_classes=len(words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 데이터 확인\n",
    "print(y_train[:5])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss확인을 위한 클래스 작성\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 및 컴파일\n",
    "history = LossHistory()\n",
    "history.init()\n",
    "\n",
    "model = Sequential()\n",
    "temp = model.add(Embedding(input_dim=len(words_set), output_dim=300, mask_zero=True))\n",
    "model.add(LSTM(units=64, input_shape=(-1, 300)))\n",
    "model.add(Dense(len(words_set), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 출력 확인\n",
    "temp1 = model.predict(x_train[0].reshape(1, -1))\n",
    "print(temp1)\n",
    "print(temp1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "model.fit(x_train, y_train, epochs=90, batch_size=128, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss 확인\n",
    "loss = history.losses\n",
    "epochs = range(len(loss))\n",
    "plt.plot(epochs, loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 테스트\n",
    "temp1 = model.predict(x_train[0].reshape(1, -1))\n",
    "print(temp1)\n",
    "print(temp1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델로 문장 생성하는 함수 작성\n",
    "def sentence_generation(model, cur_word, n):\n",
    "    sentence = cur_word\n",
    "    for _ in range(n):\n",
    "        encoded = [words_set.index(word) for word, _ in okt.pos(sentence)]\n",
    "        for _ in range(max_len-len(sentence)):\n",
    "            encoded.insert(0, 0)\n",
    "        encoded = np.asarray(encoded).astype('float').reshape(1, -1)\n",
    "        result = list(np.squeeze(model.predict(encoded))) ## encoded가 tensor가 아니고 np라서 warning\n",
    "        pred_word_idx = result.index(max(result))\n",
    "        pred_word = words_set[pred_word_idx]\n",
    "        sentence = sentence + ' ' + pred_word\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 단어로 한 문장 생성\n",
    "sentence = sentence_generation(model, '많은', len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인하기\n",
    "print(words_set[np.int(x_train[0][-1])])\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다수의 단어로 한 문장 생성\n",
    "sentence = sentence_generation(model, '힘을 잃어가고, 민속의', 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인하기\n",
    "print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
